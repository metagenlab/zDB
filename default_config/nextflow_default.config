
////////////////////
///// INPUT ////////
////////////////////

// 
params.local_assemblies = "samples.csv"


// all databases used by the different scripts should be located in this directory
params.databases_dir = "/data/databases"


//////////////////////////////
///// PROTEIN ANNOTATION /////
//////////////////////////////

params.cog = false
params.ko = false
params.pfam_scan = false

//////////////////////////////
///// QUALITY CHECK //////////
//////////////////////////////

params.checkm = true


//////////////////////////////
///// Orthology //////////////
//////////////////////////////

params.orthofinder = true
params.orthofinder_output_dir = "output"

// allow (or not) missing data when identifying single copy core genes
params.core_missing = 0
params.core_genome_phylogeny_with_fasttree = true

// build orthogroup phylogeny
params.orthogroups_phylogeny_with_fasttree = true



////////////////////////////////////////////
///// HOMOLOGY SEARCH & PHYLOGENIES ////////
////////////////////////////////////////////

// homology search vs RefSeq and SwissProt
params.blast_swissprot = false
params.diamond_refseq = false

// build phylogenies including closest BBH
// possibility to filter BBH based on phylum name
params.refseq_diamond_BBH_phylogeny = false
params.refseq_diamond_BBH_phylogeny_top_n_hits = 4
params.refseq_diamond_BBH_phylogeny_phylum_filter = '["Chlamydiae", "Verrucomicrobia", "Planctomycetes", "Kiritimatiellaeota", "Lentisphaerae"]'


//////////////////////////////
//// Chlamdb setup scripts
//////////////////////////////

params.chlamdb.db_name = "chlamdb_test.db"
params.chlamdb.db_type = "sqlite"
params.chlamdb_setup = false


//////////////////////////////
///// CONTAINERS CONFIG //////
//////////////////////////////

// Necessary to be able to access the database directory
// in singularity

singularity.runOptions = "--bind /data:/data"
singularity.enabled = true
singularity.cacheDir = "$baseDir/singularity"

// The different containers important for the pipeline
// The container can now be updated by just editing the line here
// instead of having to do it for every process using the container

// Custom containers
params.checkm_container = "metagenlab/checkm:1.0.20"
params.annotation_container = "metagenlab/annotation-pipeline:1.2.1"

// mainstream containers
params.blast_container = "quay.io/biocontainers/blast:2.9.0--pl526h3066fca_4"
params.pfam_scan_container = "quay.io/biocontainers/pfam_scan:1.6--hdfd78af_4"
params.kegg_container = "quay.io/biocontainers/kofamscan:1.3.0--0" 
params.orthofinder_container = "quay.io/biocontainers/orthofinder:2.5.2--0"
params.diamond_container = "buchfink/diamond:version2.0.11"
params.mafft_container = "quay.io/biocontainers/mafft:7.487--h779adbc_0"
params.fasttree_container = "quay.io/biocontainers/fasttree:2.1.8--h779adbc_6"
params.hmmer_container = "quay.io/biocontainers/hmmer:2.3.2--h1b792b2_5"

/////////////////////////////
///// EXECUTION CONTROL /////
/////////////////////////////

process.queue = 'normal'

// default number of cpus
// NOTE: setting up a high value may prevent nextflow from parallelizing tasks.
//  if one sets 40, with a limit of cpus of 80 (in executor), only two tasks can be launched
//  in parallel, even if they do not use multithreading (nextflow assumes that when a process is 
//  declared to use 40 cpus, it will use 40 cpus).
process.cpus = 1
params.executor = 'local'

// it is the same problem with setting a limit of memory for each process
// the limit has been removed as Asterix has 400G of memory, but it should
// be adjusted in case less memory is available

executor {
  $lsf {
      queueSize = 100
      pollInterval = '30sec'
  }
  $local {
      cpus = 80
      memory = '32 GB'
  }
}


env {
  // necessary to be able to export the python code out
  // of the main nextflow file
  PYTHONPATH = "$baseDir/bin"

  SQLPSW = "my hovercraft is full of eels"
}
